# This file was auto-generated by Fern from our API Definition.

import datetime as dt
import typing

from ...core.datetime_utils import serialize_datetime
from ...core.pydantic_utilities import deep_union_pydantic_dicts, pydantic_v1
from .top_logprobs import TopLogprobs


class LogprobsContent(pydantic_v1.BaseModel):
    """
    An OpenAI API compatible schema for logprobs output.
    """

    bytes: typing.Optional[typing.List[typing.Any]] = pydantic_v1.Field(default=None)
    """
    A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is no bytes representation for the token.
    """

    logprob: float = pydantic_v1.Field()
    """
    Logprob corresponding to the token.
    """

    token: str = pydantic_v1.Field()
    """
    New generated token or token from prompt for loglikelihood case.
    """

    top_logprobs: typing.Optional[typing.List[TopLogprobs]] = pydantic_v1.Field(default=None)
    """
    List of top tokens info.
    """

    def json(self, **kwargs: typing.Any) -> str:
        kwargs_with_defaults: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        return super().json(**kwargs_with_defaults)

    def dict(self, **kwargs: typing.Any) -> typing.Dict[str, typing.Any]:
        kwargs_with_defaults_exclude_unset: typing.Any = {"by_alias": True, "exclude_unset": True, **kwargs}
        kwargs_with_defaults_exclude_none: typing.Any = {"by_alias": True, "exclude_none": True, **kwargs}

        return deep_union_pydantic_dicts(
            super().dict(**kwargs_with_defaults_exclude_unset), super().dict(**kwargs_with_defaults_exclude_none)
        )

    class Config:
        frozen = True
        smart_union = True
        extra = pydantic_v1.Extra.allow
        json_encoders = {dt.datetime: serialize_datetime}
